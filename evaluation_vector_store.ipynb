{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52fb0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cati/.conda/envs/QuizCraft-AI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from src.model.model import MultiModalEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010de903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.4\n",
    "embedding_model = MultiModalEmbeddingModel(\"nomic-ai/nomic-embed-text-v1.5\", \"nomic-ai/nomic-embed-vision-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88164742",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exact Match - Precision/Recall/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd1ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"nomic-embed-evaluate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af149957",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"dataset.json\")\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be63804",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_chunks = [(k, elem) for k, elem in data.items() if elem[\"query\"] != \"\" and elem[\"content\"] != \"\"]\n",
    "valid_chunks = dict(valid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5dcdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = [k for k, _ in valid_chunks.items()]\n",
    "documents = [Document(page_content=v[\"content\"], metadata={\"hash\": k}) for k, v in valid_chunks.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0386dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to vector store.\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(documents, ids=hashes)\n",
    "print(\"Documents added to vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22610abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = 0, 0, 0\n",
    "queries = [(k, v[\"query\"]) for k, v in valid_chunks.items()]\n",
    "\n",
    "for k, v in queries:\n",
    "    results = vector_store.similarity_search_with_relevance_scores(v, k=1)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        doc = results[0][0]\n",
    "        score = results[0][1]\n",
    "        if doc.metadata[\"hash\"] == k and score >= THRESHOLD:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54af419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 24, FP: 134, FN: 0\n",
      "Precision: 0.1519\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.2637\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"TP: {tp}, FP: {fp}, FN: {fn}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b8645",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MRR - Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167847f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del vector_store\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"nomic-embed-evaluate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffecac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to vector store.\n"
     ]
    }
   ],
   "source": [
    "vector_store.add_documents(documents, ids=hashes)\n",
    "print(\"Documents added to vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bd8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "\n",
    "for k, v in queries:\n",
    "    results = vector_store.similarity_search_with_relevance_scores(v, k=4)\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    hashes = [doc.metadata[\"hash\"] for doc, _ in results]\n",
    "    rank = hashes.index(k) + 1 if k in hashes else 0\n",
    "    rank = 1 / rank if rank != 0 else 0\n",
    "    ranks.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2db882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.2157\n"
     ]
    }
   ],
   "source": [
    "mrr = sum(ranks) / len(ranks)\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuizCraft-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
